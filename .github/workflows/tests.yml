name: CI

on:
  push:
    branches: [main]
  pull_request:
    types: [opened, reopened, synchronize, labeled]
    branches: [main]
  pull_request_target:
    types: [opened, reopened, synchronize, labeled]
    branches: [main]
  # Manually trigger a workflow for a branch
  workflow_dispatch:
  # Merge queue trigger
  merge_group:

permissions:
  contents: read
  packages: write

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

env:
  REGISTRY: registry.gitlab.aleph-alpha.de
  REPO_OWNER: research/public-registry
  IMAGE_NAME: eval_framework
  HF_DATASET_CACHE_DIR: /tmp/huggingface_datasets  # <- single source of truth
  UV_LINK_MODE: symlink
  UV_LOCKED: 1

jobs:

  lint:
    runs-on: ubuntu-latest # default runner runs out of disk space due to hf cache
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup uv
        uses: astral-sh/setup-uv@v6
        with:
          version: "~=0.8.10"

      - name: Run Pre-Commit
        run: uvx pre-commit run --all-files

      - name: Run MyPy
        run: uv run --all-extras --group cpu mypy

  hf-datasets-cache:
    runs-on: cpu-runner-8c-32gb-01  # default runner runs out of disk space, unfortunately
    container: derskythe/github-runner-base:ubuntu-noble  # has the right python, sudo and curl:)
    steps:
      - uses: actions/checkout@v4
        if: github.ref == 'refs/heads/main'

      - name: Setup uv
        uses: astral-sh/setup-uv@v6
        if: github.ref == 'refs/heads/main'
        with:
          version: "~=0.8.10"

      - name: Huggingface datasets cache
        uses: actions/cache@v4
        if: github.ref == 'refs/heads/main'
        with:
          path: ${{ env.HF_DATASET_CACHE_DIR }}        # <- use shared env
          key: hf-datasets-${{ github.run_id }}
          restore-keys: |
            hf-datasets-

      - name: Download datasets
        if: github.ref == 'refs/heads/main'
        env:
          HF_TOKEN: ${{ secrets.HUGGINGFACE_API_KEY }}
        run: |
          uv run python -c "from eval_framework.task_names import make_sure_all_hf_datasets_are_in_cache; make_sure_all_hf_datasets_are_in_cache()"

  tag:
    runs-on: ubuntu-latest
    outputs:
      tag: ${{ steps.set-tag.outputs.tag }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    - name: Set Tag
      id: set-tag
      run: |
        if [ "${{ github.ref }}" == "refs/heads/main" ]; then
          echo "tag=latest" >> $GITHUB_OUTPUT
        else
          # head_ref is the correct branch name for PRs
          BRANCH_NAME=${{ github.head_ref || github.ref_name }}
          echo "tag=${BRANCH_NAME::20}" >> $GITHUB_OUTPUT
        fi
    - name: Output Docker Tag
      run: |
        echo "Docker Tag: ${{ steps.set-tag.outputs.tag }}"

  build:
    needs: [lint, tag]
    runs-on: cpu-runner-8c-32gb-01
    container: docker:dind
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Registry Authentication
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: token
          password: ${{ secrets.GL_PUBLIC_REGISTRY_READ_WRITE_TOKEN }}

      - name: Setup Docker BuildX
        uses: docker/setup-buildx-action@v1

      - name: Build and Push Image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: Dockerfile
          push: true
          tags: |
            ${{ env.REGISTRY }}/${{ env.REPO_OWNER }}/${{ env.IMAGE_NAME }}:${{ needs.tag.outputs.tag }}

  test-cpu:
    runs-on: cpu-runner-8c-32gb-01
    container: derskythe/github-runner-base:ubuntu-noble
    needs: [lint, hf-datasets-cache]
    steps:
      - uses: actions/checkout@v4

      - name: Setup uv
        uses: astral-sh/setup-uv@v6
        with:
          version: "~=0.8.10"

      - name: Huggingface datasets cache
        uses: actions/cache/restore@v4
        with:
          path: ${{ env.HF_DATASET_CACHE_DIR }}        # <- shared path
          key: hf-datasets-

      - name: Run tests
        env:
          HF_TOKEN: ${{ secrets.HUGGINGFACE_API_KEY }}
          HF_DATASET_CACHE_DIR: ${{ env.HF_DATASET_CACHE_DIR }}
        run: uv run --all-extras --group cu124 pytest --durations=30 -v -m "not gpu and not cpu_slow and not external_api"

  test-cpu-slow:
    runs-on: cpu-runner-8c-32gb-01
    container: derskythe/github-runner-base:ubuntu-noble
    needs: [lint, hf-datasets-cache]
    steps:
      - uses: actions/checkout@v4

      - name: Setup uv
        uses: astral-sh/setup-uv@v6
        with:
          version: "~=0.8.10"

      - name: Huggingface datasets cache
        uses: actions/cache/restore@v4
        with:
          path: ${{ env.HF_DATASET_CACHE_DIR }}        # <- shared path
          key: hf-datasets-

      - name: Run tests
        env:
          HF_TOKEN: ${{ secrets.HUGGINGFACE_API_KEY }}
          HF_DATASET_CACHE_DIR: ${{ env.HF_DATASET_CACHE_DIR }}
        run: |
          uv run --all-extras --group cu124 python -c "import nltk; nltk.download('punkt_tab')"  # otherwise there's a race condition in ntltk
          uv run --all-extras --group cu124 pytest -n auto --max-worker-restart=0 --durations=30 -v -m "not gpu and cpu_slow and not external_api"

  test-gpu:
    runs-on: EvalFrameworkGPURunner
    needs: [tag, build, test-cpu, test-cpu-slow]
    if: ${{ always()
          && needs.test-cpu.result == 'success'
          && needs.test-cpu-slow.result == 'success'
          && (needs.build.result == 'success' || needs.build.result == 'skipped') }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Huggingface datasets cache
        uses: actions/cache/restore@v4
        with:
          path: ${{ env.HF_DATASET_CACHE_DIR }}        # <- shared path
          key: hf-datasets-

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: token
          password: ${{ secrets.GL_PUBLIC_REGISTRY_READ_WRITE_TOKEN }}

      - name: Pull container image
        run: |
          docker pull "${{ env.REGISTRY }}/${{ env.REPO_OWNER }}/${{ env.IMAGE_NAME }}:${{ needs.tag.outputs.tag }}"

      - name: Run GPU tests inside container with GPU access
        run: |
          timeout 20m docker run --rm --gpus all \
            -v ${{ github.workspace }}:/eval_framework \
            -w /eval_framework \
            -e HF_TOKEN=${{ secrets.HUGGINGFACE_API_KEY }} \
            -e HF_DATASET_CACHE_DIR=${{ env.HF_DATASET_CACHE_DIR }} \
            ${{ env.REGISTRY }}/${{ env.REPO_OWNER }}/${{ env.IMAGE_NAME }}:${{ needs.tag.outputs.tag }} \
            bash -c 'uv run pytest --durations=30 -v -m "gpu and not cpu_slow and not external_api and not vllm"'

  test-gpu-vllm:
    runs-on: EvalFrameworkGPURunner
    needs: [tag, build, test-cpu, test-cpu-slow, test-gpu]
    if: ${{ always()
          && needs.test-cpu.result == 'success'
          && needs.test-cpu-slow.result == 'success'
          && (needs.build.result == 'success' || needs.build.result == 'skipped')
          && (needs.test-gpu.result == 'success' || needs.test-gpu.result == 'skipped') }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Huggingface datasets cache
        uses: actions/cache/restore@v4
        with:
          path: ${{ env.HF_DATASET_CACHE_DIR }}        # <- shared path
          key: hf-datasets-

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: "token"
          password: ${{ secrets.GL_PUBLIC_REGISTRY_READ_WRITE_TOKEN }}

      - name: Pull container image
        run: |
          docker pull "${{ env.REGISTRY }}/${{ env.REPO_OWNER }}/${{ env.IMAGE_NAME }}:${{ needs.tag.outputs.tag }}"

      - name: Run GPU tests inside container with GPU access
        run: |
          timeout 20m docker run --rm --gpus all \
            -v ${{ github.workspace }}:/eval_framework \
            -w /eval_framework \
            -e HF_TOKEN=${{ secrets.HUGGINGFACE_API_KEY }} \
            -e HF_DATASET_CACHE_DIR=${{ env.HF_DATASET_CACHE_DIR }} \
            -e VLLM_LOGGING_LEVEL=DEBUG \
            -e VLLM_WORKER_MULTIPROC_METHOD=spawn \
            -e VLLM_USE_MODELSCOPE=False \
            -e VLLM_NCCL_SO_PATH="" \
            -e VLLM_USE_TRITON_FLASH_ATTN=0 \
            -e VLLM_DISABLE_CUSTOM_ALL_REDUCE=1 \
            ${{ env.REGISTRY }}/${{ env.REPO_OWNER }}/${{ env.IMAGE_NAME }}:${{ needs.tag.outputs.tag }} \
            bash -c 'uv run pytest --log-cli-level=INFO -v -m "vllm"'
