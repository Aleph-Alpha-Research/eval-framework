<!doctype html>
<html class="no-js" lang="en" data-content_root="./">
  <head><meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="genindex.html"><link rel="search" title="Search" href="search.html">

    <!-- Generated with Sphinx 9.1.0 and Furo 2025.12.19 -->
        <title>Aleph Alpha Eval-Framework - Eval-Framework v0.2.12</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=d111a655" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo.css?v=7bdb33bb" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo-extensions.css?v=8dab3a3b" />
    
    


<style>
  body {
    --color-code-background: #f2f2f2;
  --color-code-foreground: #1e1e1e;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle site navigation sidebar">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc" aria-label="Toggle table of contents sidebar">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <span class="icon"><svg><use href="#svg-menu"></use></svg></span>
      </label>
    </div>
    <div class="header-center">
      <a href="index.html"><div class="brand">Eval-Framework v0.2.12</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="index.html">
  
  <span class="sidebar-brand-text">Eval-Framework v0.2.12</span>
  
</a><form class="sidebar-search-container" method="get" action="search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="cli_usage.html">Using the CLI</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="completion_task_guide.html">Creating Completion Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="add_new_benchmark_guide.html">How to Add a New Benchmark to Eval Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarks_and_metrics.html">Included Benchmark Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="controlling_upload_results.html">Controlling HuggingFace Upload Results Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="docker_guide.html">Docker Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluate_huggingface_model.html">How to Evaluate HuggingFace Models with Eval Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="loglikelihood_task_guide.html">Creating Loglikelihood Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_arguments.html">Model Arguments</a></li>
<li class="toctree-l1"><a class="reference internal" href="overview_dataloading.html">Overview Dataloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="understanding_results_guide.html">Understanding Evaluation Results Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="using_determined.html">Using Determined</a></li>
<li class="toctree-l1"><a class="reference internal" href="utilities.html">Utils in <code class="docutils literal notranslate"><span class="pre">eval-framework</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="wandb_integration.html">Weights and Biases Integration with Eval-Framework</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contributing Guidelines</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="CONTRIBUTING.html">Contributing to Eval Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="testing.html">Testing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="api/index.html">API Reference</a><input aria-label="Toggle navigation of API Reference" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="api/generated/eval_framework.html">eval_framework package</a><input aria-label="Toggle navigation of eval_framework package" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="api/generated/eval_framework.context.html">eval_framework.context package</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/generated/eval_framework.llm.html">eval_framework.llm package</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="api/generated/eval_framework.metrics.html">eval_framework.metrics package</a><input aria-label="Toggle navigation of eval_framework.metrics package" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="api/generated/eval_framework.metrics.completion.html">eval_framework.metrics.completion package</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/generated/eval_framework.metrics.efficiency.html">eval_framework.metrics.efficiency package</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/generated/eval_framework.metrics.llm.html">eval_framework.metrics.llm package</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/generated/eval_framework.metrics.loglikelihood.html">eval_framework.metrics.loglikelihood package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="api/generated/eval_framework.result_processors.html">eval_framework.result_processors package</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="api/generated/eval_framework.tasks.html">eval_framework.tasks package</a><input aria-label="Toggle navigation of eval_framework.tasks package" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="api/generated/eval_framework.tasks.benchmarks.html">eval_framework.tasks.benchmarks package</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="api/generated/eval_framework.context.html">eval_framework.context package</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/generated/eval_framework.llm.html">eval_framework.llm package</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="api/generated/eval_framework.metrics.html">eval_framework.metrics package</a><input aria-label="Toggle navigation of eval_framework.metrics package" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="api/generated/eval_framework.metrics.completion.html">eval_framework.metrics.completion package</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/generated/eval_framework.metrics.efficiency.html">eval_framework.metrics.efficiency package</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/generated/eval_framework.metrics.llm.html">eval_framework.metrics.llm package</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/generated/eval_framework.metrics.loglikelihood.html">eval_framework.metrics.loglikelihood package</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="api/generated/eval_framework.metrics.completion.html">eval_framework.metrics.completion package</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/generated/eval_framework.metrics.efficiency.html">eval_framework.metrics.efficiency package</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/generated/eval_framework.metrics.llm.html">eval_framework.metrics.llm package</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/generated/eval_framework.metrics.loglikelihood.html">eval_framework.metrics.loglikelihood package</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/generated/eval_framework.result_processors.html">eval_framework.result_processors package</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="api/generated/eval_framework.tasks.html">eval_framework.tasks package</a><input aria-label="Toggle navigation of eval_framework.tasks package" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="api/generated/eval_framework.tasks.benchmarks.html">eval_framework.tasks.benchmarks package</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="api/generated/eval_framework.tasks.benchmarks.html">eval_framework.tasks.benchmarks package</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="api/generated/modules.html">eval_framework</a><input aria-label="Toggle navigation of eval_framework" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="api/generated/eval_framework.html">eval_framework package</a><input aria-label="Toggle navigation of eval_framework package" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="api/generated/eval_framework.context.html">eval_framework.context package</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/generated/eval_framework.llm.html">eval_framework.llm package</a></li>
<li class="toctree-l4 has-children"><a class="reference internal" href="api/generated/eval_framework.metrics.html">eval_framework.metrics package</a><input aria-label="Toggle navigation of eval_framework.metrics package" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l5"><a class="reference internal" href="api/generated/eval_framework.metrics.completion.html">eval_framework.metrics.completion package</a></li>
<li class="toctree-l5"><a class="reference internal" href="api/generated/eval_framework.metrics.efficiency.html">eval_framework.metrics.efficiency package</a></li>
<li class="toctree-l5"><a class="reference internal" href="api/generated/eval_framework.metrics.llm.html">eval_framework.metrics.llm package</a></li>
<li class="toctree-l5"><a class="reference internal" href="api/generated/eval_framework.metrics.loglikelihood.html">eval_framework.metrics.loglikelihood package</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="api/generated/eval_framework.result_processors.html">eval_framework.result_processors package</a></li>
<li class="toctree-l4 has-children"><a class="reference internal" href="api/generated/eval_framework.tasks.html">eval_framework.tasks package</a><input aria-label="Toggle navigation of eval_framework.tasks package" class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l5"><a class="reference internal" href="api/generated/eval_framework.tasks.benchmarks.html">eval_framework.tasks.benchmarks package</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          

<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <!-- Badges -->
<div align="center">
<section id="aleph-alpha-eval-framework">
<h1>Aleph Alpha Eval-Framework<a class="headerlink" href="#aleph-alpha-eval-framework" title="Link to this heading">¶</a></h1>
<p><strong>Comprehensive LLM evaluation at scale</strong> - A production-ready framework for evaluating large language models across 90+ benchmarks.</p>
<p><a class="reference external" href="https://github.com/Aleph-Alpha-Research/eval-framework/actions"><img alt="Build Status" src="https://github.com/Aleph-Alpha-Research/eval-framework/actions/workflows/tests.yml/badge.svg" /></a>
<a class="reference external" href="https://github.com/Aleph-Alpha-Research/eval-framework/releases"><img alt="Version" src="https://img.shields.io/github/v/release/Aleph-Alpha-Research/eval-framework" /></a>
<a class="reference external" href="https://pypi.org/project/eval-framework/"><img alt="PyPI" src="https://img.shields.io/pypi/v/eval-framework.svg" /></a>
<a class="reference internal" href="#LICENSE"><span class="xref myst"><img alt="License" src="https://img.shields.io/github/license/Aleph-Alpha-Research/eval-framework.svg" /></span></a></p>
<p><a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/"><img alt="Docs" src="https://img.shields.io/badge/docs-online-blue" /></a>
<a class="reference external" href="https://github.com/Aleph-Alpha-Research/eval-framework/stargazers"><img alt="Stars" src="https://img.shields.io/github/stars/Aleph-Alpha-Research/eval-framework" /></a></p>
<p><img alt="eval-framework" src="https://raw.githubusercontent.com/Aleph-Alpha-Research/eval-framework/refs/heads/main/docs/eval-framework.png" /></p>
</div>
<section id="why-choose-this-framework">
<h2>Why Choose This Framework?<a class="headerlink" href="#why-choose-this-framework" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p><strong>Scalability</strong>: Built for distributed evaluation. Currently providing an integration with Determined AI.</p></li>
<li><p><strong>Extensibility</strong>: Easily add custom models, benchmarks, and metrics with object-oriented base classes.</p></li>
<li><p><strong>Comprehensive</strong>: Comes pre-loaded with over 90 tasks covering a broad and diverse range, from reasoning and coding to safety and long-context. Also comes with a comprehensive set of metrics, including LLM-as-a-judge evaluations.</p></li>
</ul>
</section>
<section id="other-features">
<h2>Other features<a class="headerlink" href="#other-features" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p>Flexible Model Integration: Supports models loaded via HuggingFace Transformers or custom implementations using the BaseLLM class.</p></li>
<li><p>Custom Benchmarks: Easily add new benchmarks with minimal code using the BaseTask class.</p></li>
<li><p>Custom Metrics: Easily define new metrics using the BaseMetric class.</p></li>
<li><p>Perturbation Testing: Robustness analysis with configurable perturbation types and probabilities.</p></li>
<li><p>Rich Outputs: Generates JSON results, plots, and detailed analysis reports.</p></li>
<li><p>Statistical Analysis: Includes confidence intervals and significance testing for reliable comparisons.</p></li>
<li><p>Docker Support: Pre-configured Dockerfiles for local and distributed setups.</p></li>
</ul>
<p>For full documentation, visit our <a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/">Docs Page</a>.</p>
</section>
<section id="quick-start">
<h2>Quick Start<a class="headerlink" href="#quick-start" title="Link to this heading">¶</a></h2>
<p>The codebase is tested and compatible with Python 3.12 and PyTorch 2.5.
You will also need the appropriate CUDA dependencies and version installed on your system for GPU support. Detailed installation instructions can be found <a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/installation.html">here</a>.</p>
<p>The easiest way to get started is by installing the library via <code class="docutils literal notranslate"><span class="pre">pip</span></code> and use it as an external dependency.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">eval_framework</span>
</pre></div>
</div>
<p>There are optional extras available to unlock specific features of the library:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">api</span></code> for inference using the aleph-alpha client.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">comet</span></code> for the COMET metric.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">determined</span></code> for running jobs via determined.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mistral</span></code> for inference on Mistral models.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">transformers</span></code> for inference using the transformers library.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vllm</span></code> for inference via VLLM.</p></li>
</ul>
<p>As a short hand, the <code class="docutils literal notranslate"><span class="pre">all</span></code> extra installs all of the above.</p>
<p>We use <code class="docutils literal notranslate"><span class="pre">uv</span></code> to better resolve dependencies when downloading the extras. You can install uv with:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>-LsSf<span class="w"> </span>https://astral.sh/uv/install.sh<span class="w"> </span><span class="p">|</span><span class="w"> </span>sh
</pre></div>
</div>
<p>or by follwing the <code class="docutils literal notranslate"><span class="pre">uv</span></code> <a class="reference external" href="https://docs.astral.sh/uv/getting-started/installation/">installation docs.</a></p>
<p>Now, you can safely install the project with all optional extras:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>uv<span class="w"> </span>sync<span class="w"> </span>--all-extras
</pre></div>
</div>
<p>or with pip</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>uv<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>eval_framework<span class="o">[</span>all<span class="o">]</span>
</pre></div>
</div>
<p>Tip: ensure python is properly installed with uv:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">uv</span> <span class="n">python</span> <span class="n">install</span> <span class="mf">3.12</span> <span class="o">--</span><span class="n">reinstall</span>
</pre></div>
</div>
<p>We provide custom groups to control optional extras.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">flash_attn</span></code>: Install <code class="docutils literal notranslate"><span class="pre">flash_attn</span></code> with correct handling of build isolation</p></li>
</ul>
<p>Thus, the following will setup the project with <code class="docutils literal notranslate"><span class="pre">flash_attn</span></code></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>uv<span class="w"> </span>sync<span class="w"> </span>--all-extras<span class="w"> </span>--group<span class="w"> </span>flash_attn
</pre></div>
</div>
<p>To evaluate a single benchmark locally, you can use the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>eval_framework<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--models<span class="w"> </span>src/eval_framework/llm/models.py<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--llm-name<span class="w"> </span>Smollm135MInstruct<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--task-name<span class="w"> </span><span class="s2">&quot;MMLU&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--task-subjects<span class="w"> </span><span class="s2">&quot;abstract_algebra&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output-dir<span class="w"> </span>./eval_results<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num-fewshot<span class="w"> </span><span class="m">5</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num-samples<span class="w"> </span><span class="m">10</span>
</pre></div>
</div>
<p>For more detailed CLI usage instructions, see the <a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/cli_usage.html">CLI Usage Guide</a>.</p>
</section>
<section id="benchmark-coverage-task-categories">
<h2>Benchmark Coverage &amp; Task Categories<a class="headerlink" href="#benchmark-coverage-task-categories" title="Link to this heading">¶</a></h2>
<section id="core-capabilities">
<h3>Core Capabilities<a class="headerlink" href="#core-capabilities" title="Link to this heading">¶</a></h3>
<p>Subset of core capabilities benchmarks coverd by <code class="docutils literal notranslate"><span class="pre">eval-framework</span></code>:</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p><strong>Reasoning</strong></p></th>
<th class="head"><p><strong>Knowledge</strong></p></th>
<th class="head"><p><strong>Math</strong></p></th>
<th class="head"><p><strong>Coding</strong></p></th>
<th class="head"><p><strong>Structured outputs</strong></p></th>
<th class="head"><p><strong>Long Context</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>COPA, BalancedCOPA</p></td>
<td><p>ARC</p></td>
<td><p>AIME</p></td>
<td><p>BigCodeBench</p></td>
<td><p>IFEval</p></td>
<td><p>InfiniteBench</p></td>
</tr>
<tr class="row-odd"><td><p>Hellaswag</p></td>
<td><p>MMLU</p></td>
<td><p>GSM8K</p></td>
<td><p>HumanEval</p></td>
<td><p>StructEval</p></td>
<td><p>QUALITY</p></td>
</tr>
<tr class="row-even"><td><p>Winogrande</p></td>
<td><p>Openbook QA</p></td>
<td><p>MATH-500</p></td>
<td><p>MBPP</p></td>
<td><p></p></td>
<td><p>ZeroSCROLLS</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="languages-domains">
<h3>Languages &amp; Domains<a class="headerlink" href="#languages-domains" title="Link to this heading">¶</a></h3>
<p>Subset of language-specific and domain-specific benchmarks coverd by <code class="docutils literal notranslate"><span class="pre">eval-framework</span></code>:</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p><strong>Multilingual</strong></p></th>
<th class="head"><p><strong>Specialized</strong></p></th>
<th class="head"><p><strong>Safety &amp; Bias</strong></p></th>
<th class="head"><p><strong>Efficiency Metrics</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>WMT Translation</p></td>
<td><p>MMLU</p></td>
<td><p>TruthfulQA</p></td>
<td><p>Compression ratios</p></td>
</tr>
<tr class="row-odd"><td><p>FLORES-200</p></td>
<td><p>Legal (CaseHold)</p></td>
<td><p>Winogender</p></td>
<td><p>Runtime</p></td>
</tr>
<tr class="row-even"><td><p>Multilingual MMLU</p></td>
<td><p>Scientific (SciQ)</p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>German/Finnish tasks</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="completion">
<h3>Completion<a class="headerlink" href="#completion" title="Link to this heading">¶</a></h3>
<p>Tasks focused on logical reasoning, text distillation, instruction following, and output control. Examples include:</p>
<ul class="simple">
<li><p><strong>AIME 2024:</strong> Logical Reasoning (Math)</p></li>
<li><p><strong>DUC Abstractive:</strong> Text Distillation (Extraction)</p></li>
<li><p><strong>Custom Data: Complaint Summarization:</strong> Text Distillation (Summarization)</p></li>
</ul>
</section>
<section id="loglikelihoods">
<h3>Loglikelihoods<a class="headerlink" href="#loglikelihoods" title="Link to this heading">¶</a></h3>
<p>Tasks emphasizing classification, reasoning, and open QA. Examples include:</p>
<ul class="simple">
<li><p><strong>Abstract Reasoning Challenge (ARC):</strong> Classification</p></li>
<li><p><strong>Casehold:</strong> Open QA</p></li>
</ul>
</section>
<section id="long-context">
<h3>Long-Context<a class="headerlink" href="#long-context" title="Link to this heading">¶</a></h3>
<p>Tasks designed for long-context scenarios, including QA, summarization, and aggregation. Examples include:</p>
<ul class="simple">
<li><p><strong>InfiniteBench_CodeDebug:</strong> Programming</p></li>
<li><p><strong>ZeroSCROLLS GovReport:</strong> QA (Government)</p></li>
</ul>
</section>
<section id="metrics">
<h3>Metrics<a class="headerlink" href="#metrics" title="Link to this heading">¶</a></h3>
<p>Evaluation metrics include:</p>
<ul class="simple">
<li><p><strong>Completion Metrics:</strong> Accuracy, Bleu, F1, Rouge</p></li>
<li><p><strong>Loglikelihood Metrics:</strong> Accuracy Loglikelihood, Probability Mass</p></li>
<li><p><strong>LLM Metrics:</strong> Chatbot Style Judge, Instruction Judge</p></li>
<li><p><strong>Efficiency Metrics:</strong> Bytes per Sequence Position</p></li>
</ul>
<p>For the full list of tasks and metrics, see <a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/benchmarks_and_metrics.html">Detailed Task Table</a>.</p>
</section>
</section>
<section id="getting-started">
<h2>Getting Started<a class="headerlink" href="#getting-started" title="Link to this heading">¶</a></h2>
<section id="understanding-the-evaluation-framework">
<h3>Understanding the Evaluation Framework<a class="headerlink" href="#understanding-the-evaluation-framework" title="Link to this heading">¶</a></h3>
<p>Eval-Framework provides a unified interface for evaluating language models across diverse benchmarks. The framework follows this interaction model:</p>
<ol class="arabic simple">
<li><p><strong>Define Your Model</strong> - Specify which model to evaluate (HuggingFace, API, or custom)</p></li>
<li><p><strong>Choose Your Task</strong> - Select from 150+ available benchmarks or create custom ones</p></li>
<li><p><strong>Configure Evaluation</strong> - Set parameters like few-shot examples, sample count, and output format</p></li>
<li><p><strong>Run Evaluation</strong> - Execute locally via CLI/script or distribute via Determined AI</p></li>
<li><p><strong>Analyze Results</strong> - Review detailed JSON outputs, metrics, and generated reports</p></li>
</ol>
</section>
<section id="core-components">
<h3>Core Components<a class="headerlink" href="#core-components" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p><strong>Models</strong>: Defined via <a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/evaluate_huggingface_model.html"><code class="docutils literal notranslate"><span class="pre">BaseLLM</span></code></a> interface (HuggingFace, OpenAI, custom APIs)</p></li>
<li><p><strong>Tasks</strong>: Inherit from <a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/add_new_benchmark_guide.html"><code class="docutils literal notranslate"><span class="pre">BaseTask</span></code></a> (completion, loglikelihood, or LLM-judge based)</p></li>
<li><p><strong>Metrics</strong>: Automatic scoring via <a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/benchmarks_and_metrics.html"><code class="docutils literal notranslate"><span class="pre">BaseMetric</span></code></a> classes</p></li>
<li><p><strong>Formatters</strong>: Handle prompt construction and model-specific formatting</p></li>
<li><p><strong>Results</strong>: Structured outputs with sample-level details and aggregated statistics</p></li>
</ul>
</section>
<section id="your-first-evaluation">
<h3>Your First Evaluation<a class="headerlink" href="#your-first-evaluation" title="Link to this heading">¶</a></h3>
<ol class="arabic simple">
<li><p><strong>Install the framework</strong> (see Quick Start above)</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">eval_framework</span><span class="p">[</span><span class="n">transformers</span><span class="p">]</span>
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p><strong>Create and run your first evaluation using HuggingFace model</strong>:</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">eval_framework.llm.huggingface</span><span class="w"> </span><span class="kn">import</span> <span class="n">HFLLM</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">eval_framework.main</span><span class="w"> </span><span class="kn">import</span> <span class="n">main</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">eval_framework.tasks.eval_config</span><span class="w"> </span><span class="kn">import</span> <span class="n">EvalConfig</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">template_formatting.formatter</span><span class="w"> </span><span class="kn">import</span> <span class="n">HFFormatter</span>

<span class="c1"># Define your model</span>
<span class="k">class</span><span class="w"> </span><span class="nc">MyHuggingFaceModel</span><span class="p">(</span><span class="n">HFLLM</span><span class="p">):</span>
    <span class="n">LLM_NAME</span> <span class="o">=</span> <span class="s2">&quot;microsoft/DialoGPT-medium&quot;</span>
    <span class="n">DEFAULT_FORMATTER</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">HFFormatter</span><span class="p">,</span> <span class="s2">&quot;microsoft/DialoGPT-medium&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="c1"># Initialize your model</span>
    <span class="n">llm</span> <span class="o">=</span> <span class="n">MyHuggingFaceModel</span><span class="p">()</span>

    <span class="c1"># Running evaluation on MMLU abstract algebra task using 5 few-shot examples and 10 samples</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">EvalConfig</span><span class="p">(</span>
        <span class="n">output_dir</span><span class="o">=</span><span class="n">Path</span><span class="p">(</span><span class="s2">&quot;./eval_results&quot;</span><span class="p">),</span>
        <span class="n">num_fewshot</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">num_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">task_name</span><span class="o">=</span><span class="s2">&quot;MMLU&quot;</span><span class="p">,</span>
        <span class="n">task_subjects</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;abstract_algebra&quot;</span><span class="p">,</span> <span class="s2">&quot;astronomy&quot;</span><span class="p">],</span>
        <span class="n">llm_class</span><span class="o">=</span><span class="n">MyHuggingFaceModel</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Run evaluation and get results</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">main</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p><strong>Review results</strong> - Check <code class="docutils literal notranslate"><span class="pre">./eval_results/</span></code> for detailed outputs and use our <a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/understanding_results_guide.html">results guide</a> to interpret them</p></li>
</ol>
</section>
<section id="next-steps">
<h3>Next Steps<a class="headerlink" href="#next-steps" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p><strong>Use CLI interface</strong>: See <a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/cli_usage.html">CLI usage guide</a> for command-line evaluation options</p></li>
<li><p><strong>Evaluate HuggingFace models</strong>: Follow our <a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/evaluate_huggingface_model.html">HuggingFace evaluation guide</a></p></li>
<li><p><strong>Understand model arguments</strong>: Read out <a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/model_arguments.html">Model Arguments guide</a></p></li>
<li><p><strong>Create custom benchmarks</strong>: Follow our <a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/add_new_benchmark_guide.html">benchmark creation guide</a></p></li>
<li><p><strong>Scale your evaluations</strong>: Use <a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/using_determined.html">Determined AI integration</a> for distributed evaluation</p></li>
<li><p><strong>Understand your results</strong>: Read our <a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/understanding_results_guide.html">results interpretation guide</a></p></li>
<li><p><strong>Log results in WandB</strong>: See how <a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/wandb_integration.html">we integrate WandB</a> for metric and lineage tracking</p></li>
</ul>
</section>
</section>
<section id="documentation">
<h2>Documentation<a class="headerlink" href="#documentation" title="Link to this heading">¶</a></h2>
<section id="id1">
<h3>Getting Started<a class="headerlink" href="#id1" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p><strong><a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/cli_usage.html">CLI Usage Guide</a></strong> - Detailed instructions for using the command-line interface</p></li>
<li><p><strong><a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/evaluate_huggingface_model.html">Evaluating HuggingFace Models</a></strong> - Complete guide for evaluating HuggingFace models</p></li>
<li><p><strong><a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/understanding_results_guide.html">Understanding Results</a></strong> - How to read and interpret evaluation results</p></li>
</ul>
</section>
<section id="advanced-usage">
<h3>Advanced Usage<a class="headerlink" href="#advanced-usage" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p><strong><a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/model_arguments.html">Understanding Model Arguments</a></strong> - Thorough guide on each constructor argument for salient model classes</p></li>
<li><p><strong><a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/add_new_benchmark_guide.html">Adding New Benchmarks</a></strong> - Complete guide with practical examples for adding new benchmarks</p></li>
<li><p><strong><a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/benchmarks_and_metrics.html">Benchmarks and Metrics</a></strong> - Comprehensive overview of all available benchmarks and evaluation metrics</p></li>
<li><p><strong><a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/overview_dataloading.html">Overview of Dataloading</a></strong> - Explanation of dataloading and task/sample/message structure</p></li>
</ul>
</section>
<section id="scaling-production">
<h3>Scaling &amp; Production<a class="headerlink" href="#scaling-production" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p><strong><a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/using_determined.html">Using Determined</a></strong> - Guide for distributed evaluation using Determined AI</p></li>
<li><p><strong><a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/controlling_upload_results.html">Controlling Upload Results</a></strong> - How to manage and control the upload of evaluation results</p></li>
</ul>
</section>
<section id="contributing">
<h3>Contributing<a class="headerlink" href="#contributing" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p><strong><a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/CONTRIBUTING.html">Contributing Guide</a></strong> - Guide for contributing to this project</p></li>
<li><p><strong><a class="reference external" href="https://aleph-alpha-research.github.io/eval-framework/testing.html">Testing</a></strong> - Guide for running tests comparable to the CI pipelines</p></li>
</ul>
</section>
<section id="citation">
<h3>Citation<a class="headerlink" href="#citation" title="Link to this heading">¶</a></h3>
<p>If you use <code class="docutils literal notranslate"><span class="pre">eval-framework</span></code> in your research, please cite:</p>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@software</span><span class="p">{</span><span class="nl">eval_framework</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{Aleph Alpha Eval Framework}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2025}</span><span class="p">,</span>
<span class="w">  </span><span class="na">url</span><span class="p">=</span><span class="s">{https://github.com/Aleph-Alpha-Research/eval-framework}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="license">
<h3>License<a class="headerlink" href="#license" title="Link to this heading">¶</a></h3>
<p>This project is licensed under the <a class="reference internal" href="#LICENSE"><span class="xref myst">Apache License 2.0</span></a>.</p>
</section>
</section>
<section id="id2">
<h2><br><br><a class="headerlink" href="#id2" title="Link to this heading">¶</a></h2>
<p>This project has received funding from the European Union’s Digital Europe Programme under grant agreement No. 101195233 (OpenEuroLLM).</p>
<p>The contents of this publication are the sole responsibility of the OpenEuroLLM consortium and do not necessarily reflect the opinion of the European Union.</p>
<p align="center">
  <img src="https://raw.githubusercontent.com/Aleph-Alpha-Research/eval-framework/main/docs/OELLM_1.png" width="100" style="margin-right: 50px;"/>
  <img src="https://raw.githubusercontent.com/Aleph-Alpha-Research/eval-framework/main/docs/OELLM_2.png" width="350"/>
</p>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2025, Aleph Alpha Research
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Aleph Alpha Eval-Framework</a><ul>
<li><a class="reference internal" href="#why-choose-this-framework">Why Choose This Framework?</a></li>
<li><a class="reference internal" href="#other-features">Other features</a></li>
<li><a class="reference internal" href="#quick-start">Quick Start</a></li>
<li><a class="reference internal" href="#benchmark-coverage-task-categories">Benchmark Coverage &amp; Task Categories</a><ul>
<li><a class="reference internal" href="#core-capabilities">Core Capabilities</a></li>
<li><a class="reference internal" href="#languages-domains">Languages &amp; Domains</a></li>
<li><a class="reference internal" href="#completion">Completion</a></li>
<li><a class="reference internal" href="#loglikelihoods">Loglikelihoods</a></li>
<li><a class="reference internal" href="#long-context">Long-Context</a></li>
<li><a class="reference internal" href="#metrics">Metrics</a></li>
</ul>
</li>
<li><a class="reference internal" href="#getting-started">Getting Started</a><ul>
<li><a class="reference internal" href="#understanding-the-evaluation-framework">Understanding the Evaluation Framework</a></li>
<li><a class="reference internal" href="#core-components">Core Components</a></li>
<li><a class="reference internal" href="#your-first-evaluation">Your First Evaluation</a></li>
<li><a class="reference internal" href="#next-steps">Next Steps</a></li>
</ul>
</li>
<li><a class="reference internal" href="#documentation">Documentation</a><ul>
<li><a class="reference internal" href="#id1">Getting Started</a></li>
<li><a class="reference internal" href="#advanced-usage">Advanced Usage</a></li>
<li><a class="reference internal" href="#scaling-production">Scaling &amp; Production</a></li>
<li><a class="reference internal" href="#contributing">Contributing</a></li>
<li><a class="reference internal" href="#citation">Citation</a></li>
<li><a class="reference internal" href="#license">License</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id2"><br><br></a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="_static/documentation_options.js?v=5929fcd5"></script>
    <script src="_static/doctools.js?v=fd6eb6e6"></script>
    <script src="_static/sphinx_highlight.js?v=6ffebe34"></script>
    <script src="_static/scripts/furo.js?v=46bd48cc"></script>
    </body>
</html>